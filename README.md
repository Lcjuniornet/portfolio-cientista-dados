# 💼 Portfólio de Projetos em Dados

Olá! 👋 Sou um profissional em transição para Engenharia e Ciência de Dados, com experiência prática em ERP Sankhya, automações com Java, e foco atual em dados e integração de sistemas.

Este repositório organiza meus principais projetos, divididos por níveis de complexidade. Todos os projetos foram desenvolvidos com foco em **aplicações reais**, aprendizado prático e uso de tecnologias de mercado.

---

## 🟢 Projetos Iniciais

### 📊 [Dashboard de Vendas com Power BI](https://github.com/Lcjuniornet/data-dashboard-vendas-powerbi)
> Visualização interativa de vendas por região, produto e vendedor. Base fictícia simulando uma empresa comercial.

- Power BI, DAX, Modelagem de dados
- Gráficos dinâmicos e KPIs
- Excel como fonte de dados

---

### 🚢 [Análise de Dados do Titanic](https://github.com/Lcjuniornet/data-eda-analise-titanic)
> Análise exploratória dos dados do Titanic com foco em variáveis que influenciam a sobrevivência.

- Pandas, Matplotlib, Seaborn
- Tratamento de dados nulos
- Visualização e storytelling com dados

---

## 🟡 Projetos Intermediários

### 🔄 [ETL com API e PostgreSQL](https://github.com/Lcjuniornet/data-etl-api-python-postgresql)
> Pipeline completo que extrai dados de uma API, transforma com Pandas e armazena no PostgreSQL.

- Python, Requests, Pandas
- PostgreSQL com SQLAlchemy
- Scripts modulares de ETL

---

### 🧩 [Integração Sankhya + Power BI (Simulação)](https://github.com/Lcjuniornet/data-integration-powerbi-sankhya)
> Simulação de extração de dados de um ERP para construção de dashboards operacionais.

- SQL para extração de dados
- Power BI Desktop
- Automatização de atualizações

---

## 🔴 Projetos Avançados

### 🛠️ [ETL com Airflow e Banco de Dados](https://github.com/Lcjuniornet/data-pipeline-etl-airflow)
> Pipeline agendado usando Apache Airflow para automatizar extração de dados e carga em banco.

- Python, Airflow
- PostgreSQL
- Orquestração de tarefas e DAGs

---

### ☁️ [Data Lake Simulado com Spark e MinIO](https://github.com/Lcjuniornet/data-lake-spark-simulado](https://github.com/Lcjuniornet/datalake-spark-minio).
> Simulação de um ambiente de Data Lake local, com Spark processando dados armazenados em MinIO (S3).

- PySpark, MinIO, Docker
- Processamento em lote
- Arquitetura de dados em camadas (bronze/silver/gold)

---

## 📌 Sobre Mim

- 💼 Trabalho com ERP Sankhya, automações com Java, e agora estou migrando para o ecossistema de dados
- 🎯 Em busca de oportunidades em Engenharia e Análise de Dados
- 🧠 Estudando Ciência de Dados e Engenharia de Dados com foco em projetos práticos

---

## 📬 Contato

- [LinkedIn](https://www.linkedin.com/in/seulinkedin)
- [GitHub](https://github.com/Lcjuniornet)

---

### ⭐ *Gostou dos projetos? Me dê uma estrela ou entre em contato para colaborar!*
